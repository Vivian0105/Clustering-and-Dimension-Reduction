{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huimi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.decomposition import PCA,FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24946, 2500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in=open(\"DogCatX.pickle\",'rb')\n",
    "DogCatX=pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "pickle_in=open('DogCaty.pickle','rb')\n",
    "DogCaty=pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "DogCatX=np.reshape(DogCatX,(24946,2500))\n",
    "DogCatX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DogCatX,DogCaty=shuffle(DogCatX,DogCaty,random_state=0)\n",
    "DogCatX=tf.keras.utils.normalize(DogCatX,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=20)\n",
    "X_PCA=pca.fit_transform(DogCatX)\n",
    "X_PCA=tf.keras.utils.normalize(X_PCA,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_PCA,DogCaty,random_state=5,test_size=0.25)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18709 samples, validate on 6237 samples\n",
      "Epoch 1/30\n",
      "18709/18709 [==============================] - 1s 49us/step - loss: 0.6668 - acc: 0.5886 - val_loss: 0.6445 - val_acc: 0.6248\n",
      "Epoch 2/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.6466 - acc: 0.6196 - val_loss: 0.6326 - val_acc: 0.6402\n",
      "Epoch 3/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.6365 - acc: 0.6358 - val_loss: 0.6281 - val_acc: 0.6465\n",
      "Epoch 4/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.6295 - acc: 0.6442 - val_loss: 0.6246 - val_acc: 0.6510\n",
      "Epoch 5/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.6227 - acc: 0.6486 - val_loss: 0.6254 - val_acc: 0.6460\n",
      "Epoch 6/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6172 - acc: 0.6572 - val_loss: 0.6275 - val_acc: 0.6423\n",
      "Epoch 7/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6109 - acc: 0.6609 - val_loss: 0.6253 - val_acc: 0.6447\n",
      "Epoch 8/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.6055 - acc: 0.6675 - val_loss: 0.6283 - val_acc: 0.6453\n",
      "Epoch 9/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5998 - acc: 0.6718 - val_loss: 0.6272 - val_acc: 0.6492\n",
      "Epoch 10/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5942 - acc: 0.6762 - val_loss: 0.6259 - val_acc: 0.6484\n",
      "Epoch 11/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5876 - acc: 0.6857 - val_loss: 0.6311 - val_acc: 0.6442\n",
      "Epoch 12/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5834 - acc: 0.6897 - val_loss: 0.6331 - val_acc: 0.6481\n",
      "Epoch 13/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.5760 - acc: 0.6983 - val_loss: 0.6328 - val_acc: 0.6458\n",
      "Epoch 14/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.5713 - acc: 0.6982 - val_loss: 0.6374 - val_acc: 0.6461\n",
      "Epoch 15/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.5641 - acc: 0.7079 - val_loss: 0.6454 - val_acc: 0.6399\n",
      "Epoch 16/30\n",
      "18709/18709 [==============================] - 1s 44us/step - loss: 0.5592 - acc: 0.7090 - val_loss: 0.6437 - val_acc: 0.6360\n",
      "Epoch 17/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5524 - acc: 0.7163 - val_loss: 0.6523 - val_acc: 0.6362\n",
      "Epoch 18/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5475 - acc: 0.7213 - val_loss: 0.6527 - val_acc: 0.6304\n",
      "Epoch 19/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5420 - acc: 0.7254 - val_loss: 0.6552 - val_acc: 0.6351\n",
      "Epoch 20/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.5350 - acc: 0.7325 - val_loss: 0.6662 - val_acc: 0.6360\n",
      "Epoch 21/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.5297 - acc: 0.7345 - val_loss: 0.6625 - val_acc: 0.6340\n",
      "Epoch 22/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.5229 - acc: 0.7378 - val_loss: 0.6682 - val_acc: 0.6328\n",
      "Epoch 23/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.5175 - acc: 0.7454 - val_loss: 0.6727 - val_acc: 0.6298\n",
      "Epoch 24/30\n",
      "18709/18709 [==============================] - 1s 48us/step - loss: 0.5102 - acc: 0.7473 - val_loss: 0.6770 - val_acc: 0.6319\n",
      "Epoch 25/30\n",
      "18709/18709 [==============================] - 1s 47us/step - loss: 0.5057 - acc: 0.7532 - val_loss: 0.6851 - val_acc: 0.6274\n",
      "Epoch 26/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.4980 - acc: 0.7592 - val_loss: 0.6972 - val_acc: 0.6266\n",
      "Epoch 27/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.4922 - acc: 0.7628 - val_loss: 0.7071 - val_acc: 0.6165\n",
      "Epoch 28/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.4865 - acc: 0.7682 - val_loss: 0.7034 - val_acc: 0.6234\n",
      "Epoch 29/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.4809 - acc: 0.7703 - val_loss: 0.7077 - val_acc: 0.6229\n",
      "Epoch 30/30\n",
      "18709/18709 [==============================] - 1s 44us/step - loss: 0.4742 - acc: 0.7725 - val_loss: 0.7148 - val_acc: 0.6200\n"
     ]
    }
   ],
   "source": [
    "    X_train,y_train=shuffle(X_train,y_train,random_state=0)\n",
    "    time_start=time.clock()\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history=model.fit(X_train,y_train,epochs=30,validation_data = (X_test, y_test))     \n",
    "    learn_time=time.clock()-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_time: 21.409706504807303\n"
     ]
    }
   ],
   "source": [
    "print('learn_time:',learn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA=FastICA(n_components=20,random_state=12)\n",
    "XICA=ICA.fit_transform(DogCatX)\n",
    "X_ICA=tf.keras.utils.normalize(XICA,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_ICA,DogCaty,random_state=5,test_size=0.25)\n",
    "y_train1=np.array(y_train1)\n",
    "y_test1=np.array(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18709 samples, validate on 6237 samples\n",
      "Epoch 1/30\n",
      "18709/18709 [==============================] - 1s 66us/step - loss: 0.6661 - acc: 0.5923 - val_loss: 0.6432 - val_acc: 0.6247\n",
      "Epoch 2/30\n",
      "18709/18709 [==============================] - 1s 33us/step - loss: 0.6433 - acc: 0.6260 - val_loss: 0.6354 - val_acc: 0.6405\n",
      "Epoch 3/30\n",
      "18709/18709 [==============================] - 1s 33us/step - loss: 0.6332 - acc: 0.6366 - val_loss: 0.6300 - val_acc: 0.6434\n",
      "Epoch 4/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6270 - acc: 0.6431 - val_loss: 0.6304 - val_acc: 0.6397\n",
      "Epoch 5/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6205 - acc: 0.6536 - val_loss: 0.6281 - val_acc: 0.6431\n",
      "Epoch 6/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6161 - acc: 0.6591 - val_loss: 0.6310 - val_acc: 0.6388\n",
      "Epoch 7/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6105 - acc: 0.6632 - val_loss: 0.6287 - val_acc: 0.6453\n",
      "Epoch 8/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.6038 - acc: 0.6680 - val_loss: 0.6302 - val_acc: 0.6426\n",
      "Epoch 9/30\n",
      "18709/18709 [==============================] - 1s 33us/step - loss: 0.5982 - acc: 0.6736 - val_loss: 0.6287 - val_acc: 0.6437\n",
      "Epoch 10/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5926 - acc: 0.6791 - val_loss: 0.6315 - val_acc: 0.6407\n",
      "Epoch 11/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5861 - acc: 0.6872 - val_loss: 0.6329 - val_acc: 0.6415\n",
      "Epoch 12/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5788 - acc: 0.6941 - val_loss: 0.6364 - val_acc: 0.6445\n",
      "Epoch 13/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.5733 - acc: 0.7000 - val_loss: 0.6433 - val_acc: 0.6360\n",
      "Epoch 14/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.5661 - acc: 0.7058 - val_loss: 0.6418 - val_acc: 0.6359\n",
      "Epoch 15/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.5596 - acc: 0.7121 - val_loss: 0.6470 - val_acc: 0.6391\n",
      "Epoch 16/30\n",
      "18709/18709 [==============================] - 1s 57us/step - loss: 0.5540 - acc: 0.7151 - val_loss: 0.6447 - val_acc: 0.6401\n",
      "Epoch 17/30\n",
      "18709/18709 [==============================] - 1s 44us/step - loss: 0.5467 - acc: 0.7225 - val_loss: 0.6533 - val_acc: 0.6360\n",
      "Epoch 18/30\n",
      "18709/18709 [==============================] - 1s 46us/step - loss: 0.5401 - acc: 0.7260 - val_loss: 0.6609 - val_acc: 0.6327\n",
      "Epoch 19/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.5349 - acc: 0.7295 - val_loss: 0.6578 - val_acc: 0.6375\n",
      "Epoch 20/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5278 - acc: 0.7375 - val_loss: 0.6676 - val_acc: 0.6316\n",
      "Epoch 21/30\n",
      "18709/18709 [==============================] - 1s 39us/step - loss: 0.5215 - acc: 0.7394 - val_loss: 0.6762 - val_acc: 0.6272\n",
      "Epoch 22/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5156 - acc: 0.7426 - val_loss: 0.6765 - val_acc: 0.6229\n",
      "Epoch 23/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5084 - acc: 0.7512 - val_loss: 0.6887 - val_acc: 0.6163\n",
      "Epoch 24/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.5027 - acc: 0.7571 - val_loss: 0.7011 - val_acc: 0.6224\n",
      "Epoch 25/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.4978 - acc: 0.7575 - val_loss: 0.6996 - val_acc: 0.6205\n",
      "Epoch 26/30\n",
      "18709/18709 [==============================] - 1s 34us/step - loss: 0.4907 - acc: 0.7642 - val_loss: 0.7069 - val_acc: 0.6266\n",
      "Epoch 27/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.4849 - acc: 0.7651 - val_loss: 0.7205 - val_acc: 0.6192\n",
      "Epoch 28/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.4796 - acc: 0.7696 - val_loss: 0.7122 - val_acc: 0.6187\n",
      "Epoch 29/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.4739 - acc: 0.7737 - val_loss: 0.7223 - val_acc: 0.6218\n",
      "Epoch 30/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.4684 - acc: 0.7785 - val_loss: 0.7252 - val_acc: 0.6155\n"
     ]
    }
   ],
   "source": [
    "    X_train1,y_train1=shuffle(X_train1,y_train1,random_state=0)\n",
    "    time_start=time.clock()\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history=model.fit(X_train1,y_train1,epochs=30,validation_data = (X_test1, y_test1))     \n",
    "    learn_time=time.clock()-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_time: 21.79196768712393\n"
     ]
    }
   ],
   "source": [
    "print('learn_time:',learn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCA=GaussianRandomProjection(n_components=20,random_state=3)\n",
    "X_RCA=RCA.fit_transform(DogCatX)\n",
    "X_RCA=tf.keras.utils.normalize(X_RCA,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2,X_test2,y_train2,y_test2=train_test_split(X_RCA,DogCaty,random_state=5,test_size=0.25)\n",
    "y_train2=np.array(y_train2)\n",
    "y_test2=np.array(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18709 samples, validate on 6237 samples\n",
      "Epoch 1/30\n",
      "18709/18709 [==============================] - 1s 54us/step - loss: 0.6843 - acc: 0.5503 - val_loss: 0.6779 - val_acc: 0.5703\n",
      "Epoch 2/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6767 - acc: 0.5731 - val_loss: 0.6720 - val_acc: 0.5802\n",
      "Epoch 3/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6746 - acc: 0.5779 - val_loss: 0.6718 - val_acc: 0.5806\n",
      "Epoch 4/30\n",
      "18709/18709 [==============================] - 1s 39us/step - loss: 0.6739 - acc: 0.5785 - val_loss: 0.6728 - val_acc: 0.5812\n",
      "Epoch 5/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6721 - acc: 0.5814 - val_loss: 0.6694 - val_acc: 0.5876\n",
      "Epoch 6/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6703 - acc: 0.5861 - val_loss: 0.6688 - val_acc: 0.5902\n",
      "Epoch 7/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6684 - acc: 0.5851 - val_loss: 0.6691 - val_acc: 0.5899\n",
      "Epoch 8/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6670 - acc: 0.5880 - val_loss: 0.6672 - val_acc: 0.5889\n",
      "Epoch 9/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6652 - acc: 0.5920 - val_loss: 0.6705 - val_acc: 0.5881\n",
      "Epoch 10/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6640 - acc: 0.5939 - val_loss: 0.6689 - val_acc: 0.5929\n",
      "Epoch 11/30\n",
      "18709/18709 [==============================] - ETA: 0s - loss: 0.6622 - acc: 0.595 - 1s 35us/step - loss: 0.6619 - acc: 0.5958 - val_loss: 0.6664 - val_acc: 0.5955\n",
      "Epoch 12/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6604 - acc: 0.5960 - val_loss: 0.6653 - val_acc: 0.5968\n",
      "Epoch 13/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6582 - acc: 0.6039 - val_loss: 0.6734 - val_acc: 0.5895\n",
      "Epoch 14/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6568 - acc: 0.6031 - val_loss: 0.6691 - val_acc: 0.5952\n",
      "Epoch 15/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6556 - acc: 0.6049 - val_loss: 0.6765 - val_acc: 0.5839\n",
      "Epoch 16/30\n",
      "18709/18709 [==============================] - 1s 39us/step - loss: 0.6532 - acc: 0.6093 - val_loss: 0.6707 - val_acc: 0.5899\n",
      "Epoch 17/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.6511 - acc: 0.6108 - val_loss: 0.6700 - val_acc: 0.5942\n",
      "Epoch 18/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6487 - acc: 0.6153 - val_loss: 0.6761 - val_acc: 0.5918\n",
      "Epoch 19/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6468 - acc: 0.6193 - val_loss: 0.6734 - val_acc: 0.5876\n",
      "Epoch 20/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6442 - acc: 0.6210 - val_loss: 0.6745 - val_acc: 0.5952\n",
      "Epoch 21/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6423 - acc: 0.6247 - val_loss: 0.6753 - val_acc: 0.5843\n",
      "Epoch 22/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6405 - acc: 0.6244 - val_loss: 0.6764 - val_acc: 0.5956\n",
      "Epoch 23/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6372 - acc: 0.6290 - val_loss: 0.6788 - val_acc: 0.5859\n",
      "Epoch 24/30\n",
      "18709/18709 [==============================] - 1s 40us/step - loss: 0.6352 - acc: 0.6304 - val_loss: 0.6840 - val_acc: 0.5862\n",
      "Epoch 25/30\n",
      "18709/18709 [==============================] - 1s 39us/step - loss: 0.6335 - acc: 0.6299 - val_loss: 0.6805 - val_acc: 0.5884\n",
      "Epoch 26/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6301 - acc: 0.6373 - val_loss: 0.6993 - val_acc: 0.5788\n",
      "Epoch 27/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6284 - acc: 0.6361 - val_loss: 0.6835 - val_acc: 0.5846\n",
      "Epoch 28/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6254 - acc: 0.6408 - val_loss: 0.6858 - val_acc: 0.5868\n",
      "Epoch 29/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6236 - acc: 0.6413 - val_loss: 0.6882 - val_acc: 0.5810\n",
      "Epoch 30/30\n",
      "18709/18709 [==============================] - 1s 36us/step - loss: 0.6210 - acc: 0.6453 - val_loss: 0.6883 - val_acc: 0.5860\n"
     ]
    }
   ],
   "source": [
    "    X_train2,y_train2=shuffle(X_train2,y_train2,random_state=0)\n",
    "    time_start=time.clock()\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history=model.fit(X_train2,y_train2,epochs=30,validation_data = (X_test2, y_test2))     \n",
    "    learn_time=time.clock()-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_time: 21.68751301234056\n"
     ]
    }
   ],
   "source": [
    "print('learn_time:',learn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo=cluster.FeatureAgglomeration(n_clusters=2)\n",
    "agglo.fit(DogCatX)\n",
    "X_reduced=agglo.transform(DogCatX)\n",
    "X_AG=tf.keras.utils.normalize(X_reduced,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3,X_test3,y_train3,y_test3=train_test_split(X_AG,DogCaty,random_state=5,test_size=0.25)\n",
    "y_train3=np.array(y_train3)\n",
    "y_test3=np.array(y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18709 samples, validate on 6237 samples\n",
      "Epoch 1/30\n",
      "18709/18709 [==============================] - 1s 60us/step - loss: 0.6871 - acc: 0.5444 - val_loss: 0.6791 - val_acc: 0.5708\n",
      "Epoch 2/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.6843 - acc: 0.5529 - val_loss: 0.6786 - val_acc: 0.5705\n",
      "Epoch 3/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6840 - acc: 0.5514 - val_loss: 0.6794 - val_acc: 0.5743\n",
      "Epoch 4/30\n",
      "18709/18709 [==============================] - 1s 40us/step - loss: 0.6838 - acc: 0.5560 - val_loss: 0.6803 - val_acc: 0.5657\n",
      "Epoch 5/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6836 - acc: 0.5555 - val_loss: 0.6788 - val_acc: 0.5732\n",
      "Epoch 6/30\n",
      "18709/18709 [==============================] - 1s 41us/step - loss: 0.6838 - acc: 0.5554 - val_loss: 0.6791 - val_acc: 0.5742\n",
      "Epoch 7/30\n",
      "18709/18709 [==============================] - 1s 45us/step - loss: 0.6839 - acc: 0.5552 - val_loss: 0.6804 - val_acc: 0.5652\n",
      "Epoch 8/30\n",
      "18709/18709 [==============================] - 1s 44us/step - loss: 0.6837 - acc: 0.5533 - val_loss: 0.6806 - val_acc: 0.5693\n",
      "Epoch 9/30\n",
      "18709/18709 [==============================] - 1s 40us/step - loss: 0.6835 - acc: 0.5573 - val_loss: 0.6792 - val_acc: 0.5655\n",
      "Epoch 10/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6835 - acc: 0.5544 - val_loss: 0.6793 - val_acc: 0.5663\n",
      "Epoch 11/30\n",
      "18709/18709 [==============================] - 1s 42us/step - loss: 0.6837 - acc: 0.5571 - val_loss: 0.6790 - val_acc: 0.5652\n",
      "Epoch 12/30\n",
      "18709/18709 [==============================] - 1s 40us/step - loss: 0.6838 - acc: 0.5558 - val_loss: 0.6798 - val_acc: 0.5734\n",
      "Epoch 13/30\n",
      "18709/18709 [==============================] - 1s 40us/step - loss: 0.6839 - acc: 0.5539 - val_loss: 0.6788 - val_acc: 0.5719\n",
      "Epoch 14/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6834 - acc: 0.5560 - val_loss: 0.6783 - val_acc: 0.5701\n",
      "Epoch 15/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6836 - acc: 0.5563 - val_loss: 0.6792 - val_acc: 0.5695\n",
      "Epoch 16/30\n",
      "18709/18709 [==============================] - 1s 38us/step - loss: 0.6834 - acc: 0.5571 - val_loss: 0.6794 - val_acc: 0.5684\n",
      "Epoch 17/30\n",
      "18709/18709 [==============================] - 1s 42us/step - loss: 0.6835 - acc: 0.5560 - val_loss: 0.6811 - val_acc: 0.5623\n",
      "Epoch 18/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6836 - acc: 0.5565 - val_loss: 0.6792 - val_acc: 0.5652\n",
      "Epoch 19/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6834 - acc: 0.5556 - val_loss: 0.6792 - val_acc: 0.5663\n",
      "Epoch 20/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6834 - acc: 0.5555 - val_loss: 0.6790 - val_acc: 0.5695\n",
      "Epoch 21/30\n",
      "18709/18709 [==============================] - 1s 43us/step - loss: 0.6835 - acc: 0.5565 - val_loss: 0.6793 - val_acc: 0.5666\n",
      "Epoch 22/30\n",
      "18709/18709 [==============================] - 1s 39us/step - loss: 0.6836 - acc: 0.5557 - val_loss: 0.6790 - val_acc: 0.5703\n",
      "Epoch 23/30\n",
      "18709/18709 [==============================] - 1s 45us/step - loss: 0.6835 - acc: 0.5546 - val_loss: 0.6790 - val_acc: 0.5714\n",
      "Epoch 24/30\n",
      "18709/18709 [==============================] - 1s 44us/step - loss: 0.6832 - acc: 0.5570 - val_loss: 0.6786 - val_acc: 0.5709\n",
      "Epoch 25/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6835 - acc: 0.5560 - val_loss: 0.6782 - val_acc: 0.5732\n",
      "Epoch 26/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6832 - acc: 0.5570 - val_loss: 0.6786 - val_acc: 0.5709\n",
      "Epoch 27/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6835 - acc: 0.5538 - val_loss: 0.6783 - val_acc: 0.5703\n",
      "Epoch 28/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6833 - acc: 0.5591 - val_loss: 0.6784 - val_acc: 0.5717\n",
      "Epoch 29/30\n",
      "18709/18709 [==============================] - 1s 37us/step - loss: 0.6833 - acc: 0.5547 - val_loss: 0.6796 - val_acc: 0.5689\n",
      "Epoch 30/30\n",
      "18709/18709 [==============================] - 1s 35us/step - loss: 0.6832 - acc: 0.5590 - val_loss: 0.6784 - val_acc: 0.5693\n"
     ]
    }
   ],
   "source": [
    "    X_train3,y_train3=shuffle(X_train3,y_train3,random_state=0)\n",
    "    time_start=time.clock()\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history=model.fit(X_train3,y_train3,epochs=30,validation_data = (X_test3, y_test3))     \n",
    "    learn_time=time.clock()-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_time: 23.458480411464734\n"
     ]
    }
   ],
   "source": [
    "print('learn_time:',learn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
